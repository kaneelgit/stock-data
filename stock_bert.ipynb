{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_bert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQkGEo11Ae6NOu4I4S2JNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaneelgit/stock-data/blob/main/stock_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow==2.3.0"
      ],
      "metadata": {
        "id": "6T2wTo2WY8Mq",
        "outputId": "368e6a63-4dd3-41de-b5e6-c6374308ff39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 320.4 MB 50 kB/s \n",
            "\u001b[K     |████████████████████████████████| 459 kB 40.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 64.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 35.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "jaxlib 0.3.0+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.1 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "zCcF4CLlkzAK",
        "outputId": "e3a8ebca-b1b8-46b5-b9d2-ce05532fcabe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2650, done.\u001b[K\n",
            "remote: Counting objects: 100% (2650/2650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2311/2311), done.\u001b[K\n",
            "remote: Total 2650 (delta 506), reused 1388 (delta 306), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2650/2650), 34.02 MiB | 13.81 MiB/s, done.\n",
            "Resolving deltas: 100% (506/506), done.\n",
            "Note: checking out '400d68abbccda2f0f6609e3a924467718b144233'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "Checking out files: 100% (2554/2554), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "# you may have to restart the runtime afterwards"
      ],
      "metadata": {
        "id": "Er6r--P8kvGv",
        "outputId": "91f377c6-1899-4a75-813f-6f7a141391eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 8.2 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 206 kB 33.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 331 kB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 354 kB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 39.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 29.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 36.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 43.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 35.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 29.6 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "tensorflow 2.3.0 requires scipy==1.4.1, but you have scipy 1.7.3 which is incompatible.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.0 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n",
            "google-cloud-storage 1.18.1 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n",
            "google-cloud-storage 1.18.1 requires google-resumable-media<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.2 which is incompatible.\n",
            "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.7.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.3 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.0 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n",
            "google-cloud-bigquery-storage 1.1.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.7.0 which is incompatible.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.7.0 which is incompatible.\n",
            "earthengine-api 0.1.300 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 2.39.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ETNdhAyVYleU",
        "outputId": "729f1f1a-5fe4-4bc7-dcae-5d3df4447eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get csv file\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/kaneelgit/stock-data/main/dataset_news.csv')\n",
        "\n",
        "#delete the unnamed column\n",
        "del df['Unnamed: 0']\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "g0JdP-GxZvmI",
        "outputId": "d4e070a2-12dd-49d4-b850-fa1b8564c9fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3bc83037-5333-40c8-823d-aa9ab467b6fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEWS</th>\n",
              "      <th>DATE</th>\n",
              "      <th>TICKER</th>\n",
              "      <th>SP1</th>\n",
              "      <th>SP2</th>\n",
              "      <th>SP5</th>\n",
              "      <th>SP10</th>\n",
              "      <th>W1_2</th>\n",
              "      <th>W2_2</th>\n",
              "      <th>W5_2</th>\n",
              "      <th>W10_2</th>\n",
              "      <th>W1_5</th>\n",
              "      <th>W1_10</th>\n",
              "      <th>W2_5</th>\n",
              "      <th>W2_10</th>\n",
              "      <th>W5_5</th>\n",
              "      <th>W5_10</th>\n",
              "      <th>W10_5</th>\n",
              "      <th>W10_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>City's deal with Loews rides wave of Mid-South...</td>\n",
              "      <td>2020-03-11 15:43:00</td>\n",
              "      <td>L</td>\n",
              "      <td>39.73</td>\n",
              "      <td>37.01</td>\n",
              "      <td>33.42</td>\n",
              "      <td>31.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Engine No 1, the giant-killing hedge fund, has...</td>\n",
              "      <td>2021-06-02 20:00:00</td>\n",
              "      <td>XOM</td>\n",
              "      <td>61.18</td>\n",
              "      <td>61.45</td>\n",
              "      <td>61.05</td>\n",
              "      <td>61.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is Target Unstoppable After Another Big Earnin...</td>\n",
              "      <td>2021-05-25 10:36:00</td>\n",
              "      <td>TGT</td>\n",
              "      <td>225.30</td>\n",
              "      <td>227.37</td>\n",
              "      <td>227.27</td>\n",
              "      <td>231.34</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tesla champion Ark Investment outguns Wall Str...</td>\n",
              "      <td>2021-01-31 19:00:00</td>\n",
              "      <td>STT</td>\n",
              "      <td>70.25</td>\n",
              "      <td>71.60</td>\n",
              "      <td>74.77</td>\n",
              "      <td>72.92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Here's Why NVIDIA Stock Jumped Today</td>\n",
              "      <td>2021-05-28 19:28:00</td>\n",
              "      <td>NVDA</td>\n",
              "      <td>649.78</td>\n",
              "      <td>650.58</td>\n",
              "      <td>678.79</td>\n",
              "      <td>704.76</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bc83037-5333-40c8-823d-aa9ab467b6fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3bc83037-5333-40c8-823d-aa9ab467b6fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3bc83037-5333-40c8-823d-aa9ab467b6fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                NEWS                 DATE  \\\n",
              "0  City's deal with Loews rides wave of Mid-South...  2020-03-11 15:43:00   \n",
              "1  Engine No 1, the giant-killing hedge fund, has...  2021-06-02 20:00:00   \n",
              "2  Is Target Unstoppable After Another Big Earnin...  2021-05-25 10:36:00   \n",
              "3  Tesla champion Ark Investment outguns Wall Str...  2021-01-31 19:00:00   \n",
              "4               Here's Why NVIDIA Stock Jumped Today  2021-05-28 19:28:00   \n",
              "\n",
              "  TICKER     SP1     SP2     SP5    SP10  W1_2  W2_2  W5_2  W10_2  W1_5  \\\n",
              "0      L   39.73   37.01   33.42   31.26     0     0     0      0     0   \n",
              "1    XOM   61.18   61.45   61.05   61.05     1     1     1      1     0   \n",
              "2    TGT  225.30  227.37  227.27  231.34     1     1     1      1     1   \n",
              "3    STT   70.25   71.60   74.77   72.92     2     1     1      1     2   \n",
              "4   NVDA  649.78  650.58  678.79  704.76     1     1     1      1     2   \n",
              "\n",
              "   W1_10  W2_5  W2_10  W5_5  W5_10  W10_5  W10_10  \n",
              "0      0     0      0     0      0      0       0  \n",
              "1      0     0      0     0      0      0       0  \n",
              "2      2     1      2     1      1      1       1  \n",
              "3      2     2      2     2      1      1       1  \n",
              "4      2     2      2     1      2      1       1  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df new\n",
        "df2 = df[['NEWS', 'W5_10']]\n",
        "\n",
        "# #change values\n",
        "def change_target(x):\n",
        "  if x == 2:\n",
        "    x = 1\n",
        "  \n",
        "  return x\n",
        "\n",
        "# df2['target'] = df2['W5_10'].apply(change_target)\n",
        "\n",
        "# #new dataframe\n",
        "# data = df2[['NEWS', 'target']]\n",
        "\n",
        "\n",
        "# #Plot\n",
        "# plt.plot('gains and losses after ')\n",
        "\n",
        "data = df2[(df2['W5_10'] == 0) | (df2['W5_10'] == 2)].reset_index(drop = True)\n",
        "data['target'] = data['W5_10'].apply(change_target)\n",
        "dataset = data[['NEWS', 'target']]\n",
        "# plt.figure()\n",
        "# dataset['target'].plot(kind = 'hist')\n",
        "# plt.figure()\n",
        "# plt.hist(data['target'])"
      ],
      "metadata": {
        "id": "7ypfbKsIZyAV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create tensorflow datasets\n",
        "train_df, remaining = train_test_split(dataset, random_state = 42, train_size = 0.95, stratify = dataset.target.values)\n",
        "valid_df, _ = train_test_split(remaining, random_state = 42, train_size = 0.99, stratify = remaining.target.values)\n",
        "\n",
        "train_df.shape, valid_df.shape"
      ],
      "metadata": {
        "id": "0l0IbXtac2vL",
        "outputId": "834af45b-8e94-40e3-c20b-e9d1857ac38a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17803, 2), (928, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((train_df['NEWS'].values, train_df['target'].values))\n",
        "  valid_data = tf.data.Dataset.from_tensor_slices((valid_df['NEWS'].values, valid_df['target'].values))\n",
        "\n",
        "  for text, label in train_data.take(1):\n",
        "    print(text)\n",
        "    print(label)\n"
      ],
      "metadata": {
        "id": "5Mp6NrMCho6C",
        "outputId": "bb1a678c-aa1a-4c45-fb8a-022c136daf44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'When Should You Buy Ross Stores, Inc. (NASDAQ:ROST)?', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting BERT \n",
        "\n",
        "label_list = [0, 1]\n",
        "max_seq_length = 128\n",
        "train_batch_size = 32\n",
        "\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2', trainable = True)\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokernizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n"
      ],
      "metadata": {
        "id": "-cfPn3Wfhsk_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokernizer.convert_tokens_to_ids(tokernizer.wordpiece_tokenizer.tokenize('This stock is too expensive'))"
      ],
      "metadata": {
        "id": "BvEFVoAjkjtm",
        "outputId": "cd1bdfa2-65b9-4baa-dd5d-70da5c5c1480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100, 4518, 2003, 2205, 6450]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_feature(text, label, label_list = label_list, max_seq_length = max_seq_length, tokenizer = tokernizer):\n",
        "\n",
        "  example = classifier_data_lib.InputExample(guid = None,\n",
        "                                             text_a = text.numpy(),\n",
        "                                             text_b = None,\n",
        "                                             label = label.numpy())\n",
        "  \n",
        "  feature = classifier_data_lib.convert_single_example(0, example, label_list, max_seq_length, tokenizer)\n",
        "\n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)"
      ],
      "metadata": {
        "id": "tiq-Izakh542"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_feature_map(text, label):\n",
        "\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp = [text, label], Tout = [tf.int32, tf.int32, tf.int32, tf.int32])\n",
        "\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\n",
        "      'input_word_ids': input_ids,\n",
        "       'input_mask': input_mask,\n",
        "       'input_type_ids': segment_ids\n",
        "  }\n",
        "\n",
        "  return (x, label_id)"
      ],
      "metadata": {
        "id": "d9c7qxfSivKa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  # train\n",
        "  train_data = (train_data.map(to_feature_map,\n",
        "                               num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "  .shuffle(1000)\n",
        "  .batch(32, drop_remainder = True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  \n",
        "\n",
        "  # valid\n",
        "  valid_data = (valid_data.map(to_feature_map,\n",
        "                               num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "  .shuffle(1000)\n",
        "  .batch(32, drop_remainder = True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "metadata": {
        "id": "BJmh3MdnjZUa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data spec\n",
        "train_data.element_spec"
      ],
      "metadata": {
        "id": "Ywx5v5blj-1u",
        "outputId": "9da60409-1a2f-4a22-8f18-33110e01c090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data.element_spec"
      ],
      "metadata": {
        "id": "FL9Nrr01kDaz",
        "outputId": "08fdcb1d-32a3-439e-a1aa-94b1c837898b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "\n",
        "  input_word_ids = tf.keras.layers.Input(shape = (max_seq_length,), dtype = tf.int32,\n",
        "                                         name = 'input_word_ids')\n",
        "  input_mask = tf.keras.layers.Input(shape = (max_seq_length, ), dtype = tf.int32,\n",
        "                                     name = 'input_mask')\n",
        "  input_type_ids = tf.keras.layers.Input(shape = (max_seq_length, ), dtype = tf.int32,\n",
        "                                      name = 'segment_ids')\n",
        "  \n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "  drop = tf.keras.layers.Dropout(0.4)(pooled_output)\n",
        "  output = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'output')(drop)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "      inputs = {\n",
        "          'input_word_ids': input_word_ids,\n",
        "          'input_mask': input_mask,\n",
        "          'input_type_ids': input_type_ids\n",
        "      },\n",
        "      outputs = output)\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "fs47BRJykEpk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer  = tf.keras.optimizers.Adam(learning_rate = 2e-5),\n",
        "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics = [tf.keras.metrics.BinaryAccuracy()])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "D7q-9BSEkKGF",
        "outputId": "75122fe9-496c-47db-f58b-e97c8214e759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e83101f958ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.compile(optimizer  = tf.keras.optimizers.Adam(learning_rate = 2e-5),\n\u001b[1;32m      3\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics = [tf.keras.metrics.BinaryAccuracy()])\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-de0aac65f285>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       name = 'segment_ids')\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_word_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py:237 call  *\n        result = smart_cond.smart_cond(training,\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py:509 _call_attribute  **\n        return instance.__call__(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:780 __call__\n        result = self._call(*args, **kwds)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:823 _call\n        self._initialize(args, kwds, add_initializers_to=initializers)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:697 _initialize\n        *args, **kwds))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:2855 _get_concrete_function_internal_garbage_collected\n        graph_function, _, _ = self._maybe_define_function(args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:3213 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py:3075 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:986 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:600 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/function_deserialization.py:257 restored_function_body\n        \"\\n\\n\".join(signature_descriptions)))\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'inputs_1:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'inputs_2:0' shape=(None, 128) dtype=int32>]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n"
          ]
        }
      ]
    }
  ]
}